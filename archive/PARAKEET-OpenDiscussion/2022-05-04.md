# PARAKEET Discussion


#### Wednesday, May 4th at 5 pm CET / 11 am EDT / 8 am PDT


## Agenda

* [PARAKEET with Noisy Ranking](https://github.com/WICG/privacy-preserving-ads/blob/main/NoisyRanking.md)



### Notes:

**[ PARAKEET with noisy ranking](https://github.com/WICG/privacy-preserving-ads/blob/main/NoisyRanking.md)**

**Harneet Sidhana**

As Kelda called out, our agenda for today's to talk about PARAKEET with noisy ranking for people who don't know me. My name is Harneet. I'm a product manager with the Edge team here at Microsoft. We have representations from both Edge and our ADS team today where we'll walk through PARAKEET with noisy ranking.

PARAKEET is moving forward just to set a little bit of ground rules and expectations for what parakeet is introduced. Some of the concepts that we’re going to talk about today as far as goals for PARAKEET are concerned, very similar to PARAKEET V1. We want to protect users’ privacy and provide relevant interest based ads to users. So we can keep the vibrant web ecosystem working. We do anticipate we might be able to achieve higher ad relevance than perky B1 with stronger user protection. That is why we are talking about an evolution of PARAKEET V1, which is really PARAKEET with noisy ranking, when we release PARAKEET after we started thinking about PARAKEET did some experiments. The intent with PARAKEET be one was to send noisy user signals to add tag. But add tag continues to perform selection ranking as well as auction to identify the best ad and return it to the user using Noised interest.

They're interest as we continue to evaluate PARAKEET, we realize that protecting user privacy and finding most relevant ads were at conflict with each other, and we couldn't really find an appropriate setting for anonymizing users interest, which resulted in both protecting user privacy and providing the relevant ads. We went back to the drawing board and what we've come up with is an evolution of parakeet, which is again PARAKEET with noisy ranking.

Similar to PARAKEET, we still have a concept of a trusted mediator or a trusted service.

Unlike PARAKEET, though, the trusted mediator not only is responsible for adding noise and sending noisy user information to the ad tag, but it also, in addition to that, is responsible for performing ranking of ads that are returned by the ad tag. So basically the flow is as follows. At a high level, the trusted mediator gets users information, it regulates and anonymizes user information and shares them. It had tag.

With a bunch of noise added to the user signal in response, the attack will return a collection of ads. Some of them will meet users intent, some of them will have noise, but the idea is the ad tech really, the now returns rather than a single add a collection of ads back to the mediator. The mediator then ranks those ads based on the signal that it has to find the best at amongst all those collection of ads that were returned by the ad tag.

And the trusted media at this stage can use more complete information than it has about the user. Plus the attach has ability to influence how that ranking is performed. Once the trusted mediator has found the best ranked ad amongst the collection of ads that are returned by the ad tag, it will return that add back to the browser within browser selection. Really auction continues to find the ad with the highest bid.

Any questions on that overall flow before I hand it over to Joel, who's gonna be talking about a lot of details?

**Wendell Baker**

Well, I Guess we all are kind of interested on whose behalf is this market making activity happening?

The way you told the story, the market making activity receives the suggestions from the outlying marketplaces and then in its own recognizance. It makes a decision optimizing for revenue of one or more of those marketplaces and then hands out the decision is, is that the intent here?

So the intent really is at a high level with PARAKEET. We had a trusted service whose sole purpose was to anonymize user signals and send it out to that tech.

We've realized that just anonymizing user signals does not do enough to both protect user privacy as it was originally intended, as well as find the most relevant ads. We could either do great with user privacy or do great with ad relevance, but couldn't really achieve a good balance between the two. What we are really doing is empowering the trusted mediator to not just super anonymize the user by adding noise by adding low entropy signals, but also in return once we it identifies the ads.

**Harneet Sidhana**

Once the attack identifies the ad, it also then works on behalf of those ad tech and those buyers to then find the most relevant ads within the select the selected set of ads that were returned. So the mediator is working on behalf of both the user by minimizing the check. Make sure that with the noise results that are returned it finds the best amongst those ads and returns it to the browser for the users to experience.

**Wendell Baker**

Yeah, I'll see the here because there are other questions, but I think you guys would be better served to explain, these notions of best and most relevant and so forth, and it always gets back to on behalf of the market

**Harneet Sidhana**

Yes, we will definitely talk about it, but it works on behalf of the user. Ultimately the goal is to provide users with the value that they perceive from the web. So we're not it. It works on behalf of users and that's the intent.

Both by protecting users privacy and by continuing to the continuing to keep the web open and vibrant.

**Brian May**

When you say best ad, you have to say best ad from whose perspective? If I'm an advertiser, the best ad is the ad that gets me somebody buying stuff from me or doing something that I want them to do. If I'm a publisher, the best at is he had to brings me the most revenue with the most consistency.

If I'm the user, the best ad is the one that presents me with something that's interesting to me, but I think the way that that you have things scoped.

With the original PARAKEET, we had a trip out of data which had noise added to it, and we had to figure out how to work within the bounds of the noise that was added.

Relatively straightforward to send back what we want to do, knowing that what we sent back is gonna be a pure signal, relatively pure signal that's gonna be mediated by some well-known sets of rules. ..then we look at that outcome when we consider that in terms of all of the stuff that we thought we wanted to have happen and figure out how to make what we want to have happen when you add this black box ranking in the middle of that chain, it becomes extremely difficult for us to have any idea what we need to do to optimize.

And I'm also not certain if I send back a $10 bid and everybody else sends back a dollar bid, what value is added by the ranking? Is the ranking gonna do something to preempt my $10 bid, even though my ad, according to the embeddings, is way out of space?

**Harneet Sidhana**

Great question. 

**John Mooring**

to jump in, this is detail that we're going to cover in later slides. This ranking function is totally controlled by the buyers. I don't know that that has been totally clear during the discussion up to that point.

**Harneet Sidhana**

Thanks, John. That's what I was going to mention as well. Like you are still in control of the ranking function. You still have a lot of control. It just happens in a different place on the flow to protect users against, to protect users privacy.

**Brian May**

Alright,  I'll ask again when we get there, but I'm interested in knowing when you say you have control who...

**Harneet Sidhana**

Let's pause. Let's go to the details. I think a lot of these questions will be answered.

**Joel Pfeiffer**

So this is PARAKEET V1. This is probably something people look at before that. We had sort of on the bottom there. Advertisers registering had interest for the user. And over time there’s some profile might be built up. The publisher would send for the ad request and the security services job was to basically find.

The goal was to basically find some anonymous representation of those signals, right? So you find some average IP and the middle of the space of IP. Something like this and then that ad request gets sent over to the ad network who has a lot of work to do on their side. Right? So at this point they do selection algorithms where they find presumably stuff that's somewhat relevant to what's happening. And then they do sort of a fine-tuned relevance and ranking step they do their auctions in pricing. They manage their publisher and advertiser policies and their budgets. All of that happens within the ad network and then they send us select flu few ads back to the secure service.

Which would then pass this on to the publisher with a little bit more finagling with the fine-tuned features at that stage 

Now we're moving a lot of those pieces from the ad network into the mediator itself. So in this flow you still have an advertiser creating their personalization of the user and they can really use whatever signals they want. They can use what's called the shared Storage API from to sort of put in whatever representations, whatever, side data, whatever things they feel is relevant for doing a ranking and retrieval algorithm. The trick is that the trusted Mediator now handles that ranking and relevance logic. So in this flow the publisher request adds the trusted mediator takes these raw signals and compresses them in a sense down to a an embedding space, which differentially private noise is added and sent over to the ad network. The ad network then simply does the selection, so it finds a bunch of relevant ads and sends it back to the trusted mediator. The trusted mediator now has all of the roster-that's originally available … that shared storage space that was originally on the browser is available to the trusted mediator.

They create the bids, they do their targeting and business logic here, and then the final few are sent back to an on-device auction. Basically back on browser.

Does that make sense? 

**Brad Rodriguez (Magnite)** 

Yeah, I just wanted to ask, is there a support for multiple ad networks or is it a single ad network per app?

**Joel Pfeiffer**

You can view each trusted mediator in this context is at a DSP type level or DSP crossing browser vendor type level. So in fact I would presume the implementation would do that. It makes it of course much simpler to not have DSP leakage or mistakes if you simply have them sort of spun up within their own container per DSP.

Does that make sense?

**Brad Rodriguez (Magnite)**  

It makes sense, but it doesn't seem to answer my question. So for a given ad slot, would multiple call like multiple ad networks be able to participate?

**Joel Pfeiffer**

Yes, multiple ones are able to participate. The trusted mediator does as is does not handle that. They handle it per DSP. Each DSP is results are sent back to a final option on browser & then they can compete with each other there according to SP logic.

**Brad Rodriguez (Magnite)**

OK. Thanks.

**Joel Pfeiffer**

So the main difference here is in particular that the ad ranking piece has moved right. Originally we had high dimensional private raw interest calculated by the PARAKEET, server and shared with the tech. There was no DSP control or biocontrol of this clustering process, so you know PARAKEET sort of trying to privatize things. And then they're also sort of trying to make it accurate, which are sort of two competing interests, right? There's that's gone. And so both the ranking and selections would be performed by the DSP.

Within the PARAKEET V2 proposal, the low dimensional difference with private and noise user embedding are calculated within the trusted mediator that would be shared with the ad tech. So how these embeddings are controlled is completely up to a DSP. How do they want their representation? What signals do they care about all of that wraps within their frameworks with some mild constraints? I'll have that I guess, and then we basically send this over and the DSP's do a selection, right? 

They send that back now they're at Mediator, gets all high fidelity information, they get all information from the shared storage that that the DSP wanted at a per DSP level. And they can use whatever high dimensional user information again that they want at this stage as well.

The mediator would still trying to do differential privacy, but this way through noisy embeddings, and things like the SP, they still handle final rankings across DSP's, so there's no real change there.

So why embedding? From a very sky high level embeddings are low dimensional representations of a high dimensional feature space and they have support for calculating this notion of distance and or similarity. Most models for training, not all models probably, but most are commonly doing basically a maximizing or what's called an inner product. So embeddings are nice for our tests, they're extremely well studied. In fact, embeddings are probably the cornerstone of virtually everything you see today.

With language models or image models in the machine learning community.

And as a result, finding the closest neighbors is a is a well-studied problem as well, probably predating modern neural network architectures as well. 

So, graphically sort of on the right, you can see maybe that we have  Spain and Italy, the distance and direction of Spain to Madrid in this embedding space is approximately the same as Rome to Italy in this embedding space you can also sort of see other patterns start to fall out. For example, in this 3 dimensional space, Spain, Italy and Germany are sort of somewhat clustered together as geographically maybe language wise, these are all classified together. 

Perhaps there is some noise, maybe it can't represent everything perfectly. It might not make perfect sense for Canada, Russia and Turkey to all live together. But you know, this is maybe the best we can visualize in a 3-dimensional space.

There are other thing that's really nice in addition to sort of graphically trying to understand what's happening here is it becomes easy to reason about noise and low dimensional vectors. The first thing is we can add and ensure differential privacy, and the second thing, and this is in the explainer, I won't talk about it here is we can basically estimate the amount of error that will be there if we add noise to these vectors and it hopefully will not be very much next slide please.

I'm here is 1 notion of an example that that an ad network might choose to do. On the left we had a personalization. This is sort of a user centric view. This is some summary of their behavior. We can see they've gone to do search engines. Maybe they've typed in some queries maybe and we have some, I don't know Bert. Some NLP encoder over there. We might have some sort of encoder for the browser to say, you know. Are they using Chrome, Edge, Firefox, Duckduckgo's new browser, whatever to extract that encoder out as well, and maybe these are the sequence of clicks that they've had in the last day or whatever, right. And so these are embedded down through some differentiable function, and we might have an attention network. This could be something quite complicated, like a transformer. It could also be something as similar as catenative. All these vectors together, it really is up to the DSP to decide on the right hand. We have a similar sort of architecture.

We have an ad title encoder and an ad landing page encoder. These are other NLP models ranging from whatever you know they want to provide bag of words, Transformers, things like this. They also pass through some similar combiner called the Attention Network and in the end, you have these vectors you adv. They need to be the same dimension, but that's not too complicated and the prediction really is some multiplier of an inner product space, right? And so you might. And the main thing there is sort of this linear space is the only way they're allowed to interact in the end.

The assumption or the hope is that when you train the model you're casting from a high dimensional nonlinear space into this low dimensional embedding, which is sort of linearly related to one another. Next slide please.

So our main concern here, of course, is privacy on only a noisy browser embedding is ever going to be a lot directly exposed to the mediator, so browser embedding here is sort of the condensed information about the user. This trusted mediator then runs the model that transforms the raw values into embeddings into this U vector. But what actually gets sent.. 

We'll see multivariate normals which are added in. Basically the error in the ranking like I said is bounded by the norm of that vector and we also in order to require less noise, we plan on using a randomly permuted batch to be sent over across so you can see by batching we basically have this root login factor on the denominator, meaning basically the Sigma or the standard deviation of that noise vector does not have to be quite as much. You can also think of this as sort of hiding these and the crowd, right?

Obviously we don't want to repeatedly send. We might have certain users that who hopefully are very happy on their publisher pages and they are clicking around on articles we don't want to send them repeatedly. There are maybe a handful of ways to handle this, such as a fixed noise, things like this, but that's a little bit harder to muddy out the details. So we proposed simply limiting this per user once a day to be sent over to the DSP. And we also propose a delaying these ends for users that start appearing in multiple days.

**Joel Pfeiffer**

How exactly you do this is a bit ad hoc and can be discussed. Obviously that means for some of our users we're not going to be sending this over, so we would employ basically a cache, right? So the user vector would be recomputed on the trusted mediator. So they might have new features, new signals, things like this, and they can compare against other ads the front users already on the mediator, right? .. the fall back to this cache can also be employed when we can't send a batch if there's not enough data to send the batch..

Michael, I see you have a question.

**Michael Kleber** 

Yeah. Thanks. It helps me understand some of the stuff that I was asked about in that issue. But let me just make sure I have this right. So, the noise vector that is one piece of the batch that you're sending over to the DSP that is a noise version of a dense vector space like low dimensional representation of signals that are based on both the users on device profile and the context like the publisher page that the ad is gonna appear on, right? 

**Joel Pfeiffer**

Yes, they can all feed it. They all have to feed into one model. The model can combine it however it wants. There's a constraint on the norm in particular of that vector, but otherwise it's sort of up to the yeah.

**Michael Kleber**  

Correct. So when you're talking about only sending a request for me once a day to a particular DSP, then do I understand correctly that what that would imply is like only one website per day that visit would result in that website vector going to DSP. And if I go to a different website that the DSP would not receive any signal about. 

A noise version of me on website number two, they would end up with either something based on the results from me on website one or from other people similar to me on website too, but there would be.

**Joel Pfeiffer**

So there's one send over we would like to do better, but at the moment we don't have a proof that we can do better. So the cache is obviously an important piece of this architecture, right without without sort of a good representative sample of ads in the cache, then you might be finding yourself biased towards certain publishers and what those publishers are interested into. And this is all within the DSP's control. So and and sort of if I were designing the DSP side, which I'll probably have a small hand in, I would make sure to do things like STRATIFY.

The publishers that I send back, right, if I have, you know, so I say like, you know, I so given some piece of the embedding vector which roughly a corresponds to a publisher. I can say what publishers typically are on this site. You know make sure to send stuff that they usually find relevant right. Or does that make sense.

**Michael Kleber**

OK.

**Joel Pfeiffer**

I presume they agree reporting will say that we have a bunch of ads on a certain publisher or certain trend.

Maybe I should try and stratify such that ads that are diverse across publishers are sent would be one strategy, right? Maybe I should do exploration of those fields. Things like this, but it really is up to the DSP how they handle this.

**Michael Kleber**

Right. So, I'm trying to apply this in the typical use cases that we've talked about for both fledge and PARAKEET in the past. Let's consider something like a remarketing sort of use case, right? So I'm a person who has been to Nike at some point in the past. I looked at some pair of running shoes. There's something in my on device profile that says, hey, this is a person that Nike wants to show running shoes.

OK. I guess maybe that's a bad example because maybe run Nike running shoe ads appear on Ads too. … but maybe there's an advertiser who likes some sites but doesn't like lots of sites like the advertiser wants to exert control over what sites they're ads appear on, right. So there's like 1000 different websites out there where this advertiser would wanna show me an ad for the thing I left in my shopping cart and a million websites out there where this advertiser would not wanna show me ads for things that I left in my shopping cart because they only run their ads on some publishers and not others. I'm trying to understand how that … either because of the noising that doesn't necessarily cluster sites together that way, or because of the caching because I didn't happen to go to one of the sites that advertiser likes in my one chance per day of the DSP.

**Michael Kleber**  

I see. So what you're saying is the DSP could do bidding that is based on the combination signal like the actual full vector that gets sent over, like the combination of the user signals and the contextual signals, but actually probably a lot of times the DSP would pick those apart and send back send back.

Some ads that are actually purely user targeted, even though they can't appear, or even though it's likely that they wouldn't appear on this particular thing.

**Denis Charles**

That's correct.

**Michael Kleber**  

In order to populate those ads into the cache so they hang around, and maybe that same user or a similar user shows up on a different page where those ads would appear, or sometimes later in the day. Do I understand that correctly?

**Denis Charles**

Yeah.

**Michael Kleber**

Ok great.

**Denis Charles**

Yeah, the, bidding and the ranking can depend on the two vectors inside the trusted mediator. And of course yes, if you want to, you know, increase your or decrease the loss with respect to the non private world. You would want to populate sufficient diversity inside the mediator to address these scenarios.

**Brian May**

Looks like a very rich model with lots of.

... So I don't want to ask too many questions about how it's going to work until I looked at it more closely. But I do want to ask, are there going to be multiple channels that a buyer can select from so that if they don't want to work with all of the limitations that are placed on this channel, I know that the contextual channel has been talked about as one that will always be available. But are there going to be other channels within parakeet that are less sophisticated and perhaps offer less data.

**Joel Pfeiffer**

So intuitively, I think we've sort of called this a cache…Does that make sense?

**Brian May**

What concerns me is that this is sounds like a very constrained and intricate model that you are proposing here. And I want to know, are we going to have other options aside from just contextual if we wanted to trade extra noise for less complexity is at a trade, that parakeet would make.

**Denis Charles**

I think it's in principle this is possible.

**Joel Pfeiffer**

If are you talking still about using the embeddings or are you using something else?

**Brian May**  

I'm talking about the fledge. I mean, the PARAKEET model overall. The original proposal was one that I could wrap my head around relatively easily and explain to others, which is an important aspect of ad tech, this one I think would be extremely difficult to explain to a agency or an advertiser.

**Denis Charles**

Yeah, I think in principle the question is about could we have like a standard model that is very simple to use for retrieval that they can reason about, right. And that's definitely a possibility in this world as well.

**Joel Pfeiffer**

Is that your question or were you were you thinking something else?

**Brian May**

Yes, that's essentially the question.

**Joel Pfeiffer**

OK. We can we do that.

Building a trusted model, I guess is centralized… I think the difficulty is what data we use to build such a model.

I don't think too many DSP's wants us to train it on their data and then deploy it to other people so that that will be the only place that's difficult.

**Brian May**  

So that wasn't actually my question. My question is, the original PARAKEET had we're going to add a bunch of noise. You going to be able to get the noise data, make a bit of based on that noise data and then it's going to go back and without additional interactions is going to be presented to the buyer.

In this model the data comes to us with more information. We make whatever decisions we make, we send it back. Another set of IT decisions is made and then gets presented to the buyer is a significantly more complex model to try and figure out. I'm wondering if you're going to offer the earlier model as a fall back for people who don't want to deal with complexity of this model, and I've used enough time so.

**Joel Pfeiffer**

Were open to discussing it as a fall back .. I would caution though, that I would expect that the privacy constraints on the old version make it quite a bit less accurate, but we can discuss. 

Does that makes sense?

**Brian May**

Yes, thanks.

**Joel Pfeiffer**

I guess I guess, hopefully we covered most of the last piece. It looks like Michael, you have a question?

**Michael Kleber**

Yeah, sorry. I actually just listening, listening to Brian's question.. talking about fledged particularly.. from the fledged point of view. I would say the a key advantage that the earlier version of PARAKEET had over fledge is that buyers in a PARAKEET world could more or less behave as if they were.

Buying in the old way that the that advertising used to work like the intention was that the signals coming out of the back end of PARAKEET could be roughly thought of as if they were regular old add requests coming for the browser. Sure, there's anonymization of noise that's been applied, but you could sort of buy on them as if it were the old style of the world. And maybe there would be some, you know, loss in efficiency there result. But you could kind of sweep that under the rug. 

It seems like the buyers behind this noise PARAKEET version, can't simplify it away and pretend that they're just buying in the regular old version of the world anymore. Do you agree or am I misrepresenting?

**Joel Pfeiffer**

So to some extent, although I do want to emphasize again this notion of like catch right, I don't see any restrictions with things like if they're willing to move their corpus into such a cache, where there are tight constraints over basically what data ever leads it. Does that make sense? There's no constraints in this in this world on how we still need to design the cache. So. So obviously a lot of outside influence might be good there to say, you know, it would be really nice if I could look up a publishers.

I advertiser block list right so I have I have some publisher a particular news site perhaps and I don't want my product to be shown on their page right? So it would be it would be really nice if you had a way that I can push a big a key store table into this quote cache even though it's not really a cache if I'm using it this way and then my workload can now look this up and say OK well I have all these ads and this advertiser said they don't want just lower the bid to negative four... Does that make sense?

**Michael Kleber** 

Yeah. Totally that. OK. Well, you're sort of forcing my hand now. OK, so I am going to keep thinking about this as compared to fledge. So, what you're saying now is starting to sound to me as if a way of thinking about PARAKEET here is pretty similar to.

**Michael Kleber**  

Fledge, which is to say there's a key value store and you can push all the data you want into the key value store and the the interest group on the browser has a bunch of keys which control what data it looks up from. The key value store and then in the fledge model the result of looking something up from the key value store is an on device computation that uses that data plus the raw user signals to do arbitrary computation for bidding. And here that happens on a server instead like here you have a server instead of purely on device computation that is taking in the look up.

**Joel Pfeiffer**

So, so speak about pledge that actually has allowed to do with the next slides. Anyways, there's a lot shared right as far as what exactly does a publisher need to do? What exactly does a advertiser need to do and what exactly you know, like how do they plug it? And basically it plugs in in a very similar way. There is already a joint add interest group and a run ad auction. These already exposed pretty much everything we need the joint ad interest group.

**Joel Pfeiffer**

And there is basically an extra flag for an enabled shared stories work let you know some turned me on please, and here's some additional junk that I want you to do computations with. Right your work on device can do whatever the heck they want. They can create a large vector. I don't know a details on the shared storage API. Enough to say if it would cap you at some point, but regardless, you have to work within that constraint. But it's it. That's it. I and emphasize that this could be anything from like what? We envision, which is these vectors, right? These high fidelity like maybe you take a hash of the domains and you put it in a multi hot vector reps bar surface annotation to feed into a model. 

This is is similar again, so there's an open RTB request to gather publisher signals front. You know that passes through the SP which says I want these DSPS and it sends data over to them. There's a little bit of information that DSP needs to provide like, yes, I want to run PARAKEET. Yes, I want to. And oh, by the way, the PARAKEET service that we use is provided by example.com. Things like this. I think it's important to remember that as designed there's no guarantee that every browser vendor will use their own.

Of course these mediators will be set up. I think that's an open question for all of these proposals today, although I I believe Google recently published a flow for how you might at least validate them in some way, which I encourage people to look at.

We've regardless sort of you take the top view, anything that sort of clears whatever hurdles that DSP might have. They return to the browser, there's an additional fledge option, right? So this is where your SP really can influence things. And there's other business auction ranking that might happen at this stage and then at the end you sort of go out to some other trusted CDN to actually get the creative right and return it.

So we basically envisioned this plugging into whatever we have. There's a bunch of proposals for attribution reporting and things like this, but basically events occur and in order to train the model, the trusted mediator of course needs to know that these events occurred or it can't train anything because it doesn't have a label. So these sorts of events like they view it, they click it, maybe they convert those, all things need to be sent to the trusted mediator. As far that we then would do like a reporting and training step.

… at some point basically you have a model you're happy with, you return the model, there will be constraints on how often you can return an add embedding model, because of course if you train a billion times on one sample, you can probably figure out what that sample was, right? So there do need to be some, some simple, you know, some sort of constraints on how that works exactly, which we haven't thought through all the way. They have to make adoption transparent through this JavaScript tag. They provide the workloads and and the models basically right. So the worklist translate these raw features, there's an they store user information on the site about the site and the browser.

**Joel Pfeiffer**

They also sort of produce provide the model representation. I want to be clear about that. I I think I initially we'll have a bring your own model approach perhaps. But in the end sort of they have to provide an initial starting point and that's all they get. So it might in some cases be random, it might be some pre trained transformer model downloaded from hugging face, I don't know but that that's up to them and then they need this script that does ranking at the end.

They determine environments, they get to pick the DSP and of course they own the final auction, right? So all the all the bids that come in from the DSP's.

Training models on we've largely picked this down the road. I feel it is an important topic to make sure data does not leak back here. However, my own intuition and conversations with sort of the privacy team at Microsoft Research make it very clear that of course the main exposure is going to be from any.

I think that's it, are there any follow up questions you have? It looks like 10 more minutes at least so.

**Wendell Baker**

I don't have a question so much a comment, so thanks for presenting this. I think it's important to have received the verbal on this. I know you guys published the written work... proofs of that in the realm of demonstrations and availability that would be very, very helpful… it needs to be conveyed to those of us outside that we're going to run our business on this.

**Denis Charles**

I'll probably say one thing about the motivation of this. You know, this effort in addition to addressing the issues with the previous parakeet, was we needed a way to mathematically reason about what happens if we add noise to the request setup being sent to the ad network. And that's the reason why we had to go in this direction because that's kind of what we were trying to do is trying to minimize the differences to the current world in terms of the quality of the ads being matched.

Mathematical structure term reason about this, that's the basis for the change.

**Joel Pfeiffer**

Are there any other questions or we can give her?

**Brian May**  

Pretty different from what we're used to. As I mentioned earlier, there's a lot of constraints here that we haven't previously had to deal with and that we're going to have to figure out how to navigate. And the more that we can get help in the way of feedback from the PARAKEET folks, that demonstrates how it's going to work in real life, the easier it is for us to sell it.

So we did want to get feedback before diving completely in. And I would also add that any, any sort of additional feedback that you come up with over the next couple weeks, of course, please add issues on the repo so that we can address. Like I said, there are key parts that are not.

**Grant Nelson** 

I have a question, is this version of PARAKEET designed to be a better alternative for retargeting than fledge.

**Joel Pfeiffer**

I’m not sure I would characterize as strictly better. 

Jim simply from a you know this mediator should be able to handle a lot more data, right? I can handle a lot more space than a than a user's cell phone, right? 

**Michael Kleber**  

OK, so in thinking about this as compared to something that is basically fledge accept that all of the heavy computational aspects of fledge happen inside of trusted server instead of on the device, right? Let's think about.

Uh, which fledged does on device and so there's all these constraints. So let's say we can remove all of those. Uh, how many compute constraints there are. You can run arbitrary ML models on the real signals that are stored on device, and the real contextual information inside of this.

Then I'm trying to think of what the what the advantage of the of the noisy PARAKEET proposal is over fledged. The over this kind of fledge with server-side support where it seems like the big difference here is that in fledge with server side support like the pool of ads that you're looking at that you're that you're considering is at the time the user is added to an interest group, the Advertiser said, hey, here's a pile of ads that this interest group might.

Show right and every day there's another opportunity to say, or every periodic update, whatever it is, there's another can do. Different ads that the this interest group might show. And it seems like the difference is that in the PARAKEET model, the server side cache is a new additional source of ads that might get shown that can be pushed kind of attached to these signals arbitrarily. And so they're not 

**Joel Pfeiffer**

Well, it allows the DSP to have a lot more control over what gets sent over the trusted mediator. I don't know about Google, but we have a lot of content that probably wouldn't get pushed very often.

So things like this, right? It gives them a lot more control over what goes the TM. They don't really have to use the cache if they don't want to.

Things like this right?

**John Mooring**

So I just cut in here and also mentioned that in fledge when you're selecting ads for an interest group, you're limited to user signals.

Well, we're right at 9:00 o'clock and I don't see any other questions in the queue. So why don't we go ahead and finish? I would also say please of course raise issues in the and the explainer as you see it as we sort of move forward into this design, I think it will actually be very helpful to know how people really intend on using it initially and what sort of features they would like to be built in, right.

**Brian May**

Thanks folks and thanks for the explanations.

**Joel Pfeiffer**

Alright, thank you.
