<!-- Output copied to clipboard! -->

<!-----
NEW: Check the "Suppress top comment" option to remove this info from the output.

Conversion time: 1.569 seconds.


Using this Markdown file:

1. Paste this output into your source file.
2. See the notes and action items below regarding this conversion run.
3. Check the rendered output (headings, lists, code blocks, tables) for proper
   formatting and use a linkchecker before you publish this page.

Conversion notes:

* Docs to Markdown version 1.0β29
* Wed Apr 21 2021 12:43:17 GMT-0700 (PDT)
* Source doc: PARAKEET
* This is a partial selection. Check to make sure intra-doc links work.
----->



# PARAKEET Discussion

**Wednesday, April 21st at 5 pm CEST / 11 am EDT / 8 am PDT**

Open discussion to review technical details and open[ GitHub issues](https://github.com/WICG/privacy-preserving-ads/issues) for the PARAKEET proposal.

## Agenda

1. [Open Issue #14 ](https://github.com/WICG/privacy-preserving-ads/issues/14) - [PARAKEET in JavaScript?](https://github.com/WICG/privacy-preserving-ads/issues/14)
2. [Open issue #11](https://github.com/WICG/privacy-preserving-ads/issues/11) - [Publisher–SSP collusion risk ](https://github.com/WICG/privacy-preserving-ads/issues/11) 
3. [Open Issue #13](https://github.com/WICG/privacy-preserving-ads/issues/13) - [MaCAW with FLEDGE-style contextual signals C ](https://github.com/WICG/privacy-preserving-ads/issues/13) 


## Attendees:



1. Kelda Anderson (Microsoft)
2. Mehul Parsana (Microsoft)
3. Brian May (dstillery)
4. Erik Anderson (Microsoft)
5. Brendan Riordan-Butterworth (IAB Tech Lab / eyeo GmbH)
6. Brad Rodriguez (Magnite)
7. Michael Kleber (Chrome)
8. Newton (Magnite)
9. Chris Starr
10. Przemyslaw Iwanczak (RTB House) 
11. Anthony Molinaro
12. Aswath Mohan(Microsoft)
13. Derrick Fu (Microsoft)
14. John Mooring (Microsoft)
15. Grzegorz Lczba
16. Matt Wilson
17. Kiran
18. Joel Meyer(OpenX)
19. Michael L
20. Jeff Kaufman (Google)
21. Russell Stringham
22. Valentino Volonghi (NextRoll)
23. Andrew Pascoe (NextRoll)
24. Matt Wilson (NextRoll)
25. Mike Pisula
26. W Baker 
27. Ash
28. Newton Koumantzelis
29. Nishath Chandran (Microsoft)

## Notes:

**Mehul Parsana**: thank you everyone for joining

There are 3 agenda items today

We will start w/ the [Publisher–SSP collusion risk ](https://github.com/WICG/privacy-preserving-ads/issues/11) 

We will focus on parakeet first and will expand t MaCAW in next weeks Web-Avd presentation

**Mehul**: The publisher context is not given in the interest group/bid request to the DSP is the collusion risk where if the publisher has a user ID based on contextual info, working with a DSP it can say "for this contextual request this is the user ID," then the SSP and DSP which had partial info can try to remember that user ID and keep using it in the future.

PARAKEET adds some Risks

**Michael Kelber**: that is a great summary - one callout - 

Want to make clear that a lot of it is about if there's a timing attack. I agree that the anonymization through the proxy can do a lot to anonymize c' and s' but we're talking about a situation where the browser is able to talk directly to anyone not through the proxy as well. Two different requests from the browser to the ad network, one through proxy with anonymized signals, and one directly. Because those two requests happen at nearly the same time, it seems very difficult to avoid the joining of them.

**Mehul**: thanks, yep, the time correlation will happen because a pixel or other tracker might send all of "c" at page load time. The answer is… the time-based join is based on contextual signals, IP, and user agent. This will typically be called fingerprinting or the equivalent of that.

We have two constructs-- context anonymization that checks within a time window if the signal in the parakeet request is valid for k users and it might truncate all the way up to domain name and ad size.

 

There's another thing that we didn't explain well-- there's another thing called a spurious ad request such that the ad network could join c' and c, but it's still unsure which s' is the right one. It's possible, but trying to make it hard to use in a scalable way. This has a cost one way or the other. With the second layer of protection the user features that are learned for that user ID are differentially private user features.

Is there user linkage w/ the advertiser .com site?

User ID linkage will still not be possible, user interest will be learned but at the cohort level. 

The Ad network could pick up one of 10 signals, while it still could be possible to fingerprint the differentially private user features it would be harder and more expensive.

The third thing I want to clearly explain… the user features s' that looks like it's going in plaintext; in the true system-level thing they are encrypted by the DSP or whoever the reader is by their public key. Only people who are allowed to read or have the private key to decrypt will get the s'. It's never fully readable, but we did a privacy analysis on the full vector. It's partitioned by DSP and what they're able to decrypt unless everyone shares each others' keys with each other, which is unlikely, but it's a bit of game theory. So, that's another expensive step for linkage and joining.

 

Not saying a crafted attack may not be possible. Attacking a specific user may be possible but will be very hard to prevent in any setup unless you put a lot of cryptographic things that encrypt everything. Michael, does this answer your question, or do you still see a risk with c' or is there sufficient protection?

 \
**Michael Kleber**: two different things you said that caught my attention. First of all, there's separating out different information going to parties is encrypted differently that I haven't spent a lot of time thinking about. Anytime you're talking about transforming the set of on-device user features _s_ to _s'_ there are interesting questions about how you make that coarsen that vector. That raises a bunch of interesting questions about how much your coarsening affects different amounts of info people get; is it beneficial for some people to collude or not collude because of the info that makes it through the coarsening process. Details about how that coarsening works with multiple players would be interesting. I know you said you're working on a prototype for the service.

**Mehul**: Yes, we just talked about one approach for coarsening _s_. When we open it up, I'm sure we can have folks chime in and make it more robust. We've been thinking more about batched differential privacy. Otherwise, advertiser-by-advertiser, you need just 33 bits to keep everyone's user IDs on their own.

**Michael Kleber**: The other thing you said besides the s to s' thing is this notion of introducing spurious requests with the right context but random other possible values for coarsened user data. Letting the true thing hide in the chaff of fake ad requests seems like an interesting approach. Similar to private information retrieval. I don't know how ad buyers will feel about it-- because they might go from 1 ad request to 10 they need to return. Ad buyer resource usage concerns may have some opinions.

**Mehul**: One spurious ad request is needed only when c' doesn't pass k-anonymity. Lots of traffic in top pages, but the web is a long tail. Top pages shouldn't need spurious ad requests. The spurious ad requests for batching _k_ requests it achieves the spurious thing but introduces the latency thing. Batch it for 10 20 S - you are then serving X requests instead of 1. Now the overhead is suddenly reduced because you're serving _k_ of them. Batching 10 ad requests, it may be 1:1.

**Michael L**: want to clarify something you said. Small publishers may be too small to hit an anonymity threshold. This might allow a small publisher to still participate and send a user signal but with spurious requests, it might be able to participate.

It would allow small publishers to send a request with a user signal w/o risking user data.

**Mehul**: yes, we just talked about one approach for coarsening _s_. When we open it up, I'm sure we can have folks make it more robust. We've been thinking more about batched differential privacy. Otherwise advertiser-by-advertiser you need just 33 bits to keep everyone's user IDs on their own.

**Michael L**: Yes, that is interesting, thank you.

**Mehul**: MaCAW helps with some of this but it adds a lot of complexity. Would like to figure out how to make the more basic model will work.

Next up-we will move on to [Open Issue #14 ](https://github.com/WICG/privacy-preserving-ads/issues/14) - [PARAKEET in JavaScript?](https://github.com/WICG/privacy-preserving-ads/issues/14)

**Erik**: super interesting comment I was not previously aware that Google was working on a FLEDGE Polyfill.

We are interested in collaborating & are working to publishing our V0 prototype. We would like to talk about being able to merge the two and being able to support multiple models where there are API similarities or deltas. Jeff do you have any high-level polyfill consideration you want to share?

**Jeff Kaufman**: One question we have not fully sorted out is whether we are building out a polyfill for experimentation for testing internally or if we can build a polyfill we can trust to handle user data.

**Erik**: That is a great question.  We would like folks to be able to use this for real analysis. There may be some limitations that come up. Do we punt some of the concerns to the folks hosting the polyfill library? This could simplify but could but limits the analysis use for privacy purposes .. this is something we will iterate on more.

**Erik**: Providing a polyfill library experimentation context: Browsers are always evolving they add new APIs or capabilities - so Polyfills do not always have 1:1 w/ native capabilities but you can get pretty close.

The intent is toe be able to evaluate the API w/ out building out the whole API in the browser and allows folks to test it out. For these libraries there is some utility of what changes you would need to change to call this API. Can provide more approachable steps to start testing & analysis on revenue impacts. 

**Jeff Kaufman**: One way that is a little bit different between FLEDGE and Parakeet is that FLEDGE is pretty much an entirely client-side API for the server-side - each company is going to make their own server-side component.

Parakeet, you have this separate server-side component that the browser vendor would build. Do you have a draft version of this - Who would host that? Are you planning to simulate this in the client instead?

**Erik**: For the server-side, we are also working on a prototype design that is where we are working to figure out how to let folks hook up to the polyfill to this service.

**Mehul**: If you look at the server component in the parakeet V0 flow it's doing 2 things but it's not changing any schema or the API flow or parameters. It is sitting in-between and truncating the signal.

For testing purpose we will start simple and will iterate into the larger changes.

We will have some server component but will work with folks to develop the correct flow. 

**Mehul**: We also have one question regarding how you will keep the user interest data, top-level domain, cross-level domain in the iframe.

 

**Jeff**: We're planning to use a cross-domain iframe with IndexedDB inside that iframe. That lets you have some info you can access any different 1p context, and then you can use JS running in that iframe to perform some access control to ensure folks only manipulate the cross-domain.

 

Also, feel free to post questions on our Github repo.

**Mehul** next up is  [Open Issue #13](https://github.com/WICG/privacy-preserving-ads/issues/13) - [MaCAW with FLEDGE-style contextual signals C ](https://github.com/WICG/privacy-preserving-ads/issues/13) 

**Michael Kleber**: related to what we were talking about in the earlier conversation. This relates to conversations we've had on FLEDGE.

 

There's been a bunch of discussion in the Web Adv BG about ways in which these sort of special ad requests which have special treatment like FLEDGE or PARAKEET interact with ad request that don't get this special augmented info attached to them.

It could include purely contextual targeting, direct-sold ads, other deals the publisher has with other parties-- lots of ways not going through SSP or DSP that ads might show up. This is about the relationship with these various types of ads.

 

It seems to me that on the publisher page, before a PARAKEET ad request happens, there could be an interaction between the publisher page and various servers belonging to other ad tech companies, which could provide info to influence the PARAKEET ad request.

 

I wanted to make sure that at the time the page loads, there could be communication between the page and various ad servers that only have contextual info. Those could respond with contextual ad targeted candidates, and also those interactions with other ad servers could provide contextual signals that could affect the value c that turns into c' in the PARAKEET server.

 

**Mehul**: yes, that's where you're saying it's similar to FLEDGE. Yes, when we say the context c is converted into some representation c'. To reduce the privacy risk, we assume c' is not a runtime construct. For every page, it should statically map to the content of the page. When you make a runtime request to the publisher, it could contain the user ID, and the publisher user ID should not influence c or c'.

 

I think FLEDGE needs to have that so bid requests have a more limited signal.

 

The c is assumed to be dependent on user content only. Now direct-sold ad retrieval is a separate runtime ad request. That's why we're treating direct-sold as a different problem than getting the contextual signal for the page.

 

We could optimize the flow so not every time we reach out to the SSP it has to get the contextual signal c; it could be in a header or relatively static.

 

**Michael Kleber:** that's interesting and not the answer I was expecting. Sorry, I was busy and didn't look at your response yet. If I understand correctly, there's a use case we've talked about that maybe doesn't fit into the PARAKEET model. If you consider the situation where the publisher builds their own segments, they watch everything you do on their web site… the newspaper I visit all the time might know I'm interested in tech stories even when I'm reading an article that's not about tech. FLEDGE considers any info about the page but also anything their 1p understanding of who the user is. It sounds to me like you don't want the contextual info to include 1p info about the user that might differ on a user-by-user basis. That would make it hard for the publisher to say, "hey, DSP and SSPs of the world, feel free to run an auction for this page; it's a page about the Mars landing that just happened, but it is also being read by a person that reads sports pages about basketball." Maybe this doesn't fit into the PARAKEET flow at all.

 

**Mehul**: right, the way we foresee that happening is in two directions: (1) direct-sold ad using only publisher context and work with the DSP to get that ad back; (2) the publisher could add the user to the interest group s for a user interested about sports, and that could go as part of the user features. That's also where it goes together to be scrutinized for the same privacy cost.

 

**Michael Kleber:** Okay. To say back to you what I think you said to make sure I understood it: if I'm on NYT on a page about Mars landers and a frequent sports user, the fact that the user is on a page about the Mars lander would be in c (not based on who is visiting) and the fact that NYT knows I read about sports a lot would be s, but it would be a user signal only available when I'm on NYT. Doesn't need to be a global s that follows me around.

 

**Mehul**: yes, that's where the access control happens such that only NYT can read it.

 

**Michael**: to get back to the question I had in #13 for the data flow between a separate request outside of PARAKEET… suppose I go to the NYT page, there's a header bidding request with no user signals at all (just contextual info/1p audience info, just lacking cross-site info), the response comes back for some other ad, and PARAKEET request could be affected by that ad request and could plausibly affect both c and s since NYT might use this ad server to assign topic categories the user is interested in for brand safety reasons and they might also be responsible for looking up that user's 1p cookie with a profile about the user that says they're a sports reader. The job of splitting the signals between c and s needs to be thought about in the flow between the browser and this outside ad server before the PARAKEET request even happens.

 

**Mehul**: user feature would still be part of the ad request. You're sort of saying the same thing-- it would say to assign the feature now that I've seen the user looking at it. However, c and c' we'd like to get it cached for the page so we don't need to reach out to grab contextual signal every time to cut the latency. The direct-sold ad would be a runtime request, it could go in parallel and not need sequentiality.

 

As far as if it's a FLEDGE-style request and could it be aligned, I guess "yes". In terms of the API flow, it could be the same thing, that's not a big difference if you want to align. The larger difference is the second request where FLEDGE allows no contextual signals while PARAKEET says we can analyze them.

 

**Mehul**: I also have had direct-sold and header bidding. Aram had posted on the Web Advertising BG forum. We'll come back to it.

 

**Aswath**: we know there are other proposals outside of browser proposals with UID, server-to-server flows in other forums. The ability for a publisher to rationalize multiple ways to get ads-- is there a forum for that?

**Michael**: There is an old issue opened on turtle dove but has not been flushed out - would be a sequence of alternating issues. It's this one: https://github.com/WICG/turtledove/issues/59 
